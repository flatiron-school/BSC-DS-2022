{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# $k$-means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from sklearn import datasets\n",
    "\n",
    "# import Alison's code for the demo clusters\n",
    "import src.demo_images as demo\n",
    "from src.k_means_plotter import k_means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Learning Goals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Assess what scenarios could use $k$-means\n",
    "- Articulate the methodology used by $k$-means\n",
    "- Apply KMeans from sklearn.cluster to a relevant dataset\n",
    "- Select the appropriate number of clusters using the elbow method and Silhouette Scores\n",
    "- Evaluate the weaknesses and remedies to $k$-means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## A Classic Scenario\n",
    "\n",
    ">You work for the marketing department within a large company that manages a customer base. \n",
    "For each customer you have a record of average purchase cost and time since last purchase.<br> \n",
    "You know that if you want to retain your customers you cannot treat them the same. You can use targeted marketing ads towards groups that demonstrate different behavior, but how will you divide the customers into groups?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Clustering!   Finding **GROUPS**\n",
    "\n",
    "How many groups do you see?\n",
    "\n",
    "<img src=\"images/initialscenario.png\" width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Wait - How is clustering different from classification?\n",
    "\n",
    ">In _classification_ you **know** what groups are in the dataset and the goal is to _**predict**_ class membership accurately.\n",
    "\n",
    ">In _clustering_ you **do not** know which groups are in the dataset and you are trying to _**identify**_ the groups.\n",
    "\n",
    "Because we do not have target labels, clustering is a form of machine learning called **unsupervised learning**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### So what do you do with clustering results?\n",
    "\n",
    "Clustering is often an *informing* step in your analysis. Once clusters are identified, one can:\n",
    "- Create strategies on how to approach each group differently\n",
    "- Use cluster membership as an independent variable in a predictive model\n",
    "- Use the clusters as the _**target label**_ in future classification models. How would you assign new data to the existing clusters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Explore the algorithm with an intuitive K means approach\n",
    "\n",
    "### Observe the following four methods with a sample dataset:\n",
    "\n",
    "### Method Questions:\n",
    "\n",
    "- What do they have in common?\n",
    "- What are the differences between them?\n",
    "- How many groups are there in the end?\n",
    "- Do you see any problems with this method?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Method 1 | Method 2 |\n",
    "| -------- | -------- |\n",
    "| <img src=\"images/from-left.gif\" width=400> | <img src=\"images/from-right.gif\" width=400> |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Method 3 | Method 4 |\n",
    "| -------- | -------- |\n",
    "| <img src=\"images/from-top.gif\" width=400> | <img src=\"images/from-bottom.gif\" width=400> |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "In common:\n",
    "\n",
    "- \n",
    "\n",
    "\n",
    "Differences:\n",
    "\n",
    "- \n",
    "\n",
    "\n",
    "Groups:\n",
    "\n",
    "- \n",
    "\n",
    "\n",
    "Problem with this method?\n",
    "\n",
    "- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### K-means algorithm, at its core, in an optimization function\n",
    "\n",
    "<img src=\"images/minmaxdata.png\" width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Reassigns groups and adjusts centroids to...\n",
    "\n",
    "<img src=\"images/min.png\" width=700>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### And to...\n",
    "\n",
    "<img src=\"images/max.png\" width=700>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Sci-kit Learn** documentation actually has some pretty good [documentation describing the algorithm](https://scikit-learn.org/stable/modules/clustering.html#k-mean) if you wish for more detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Challenges of Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = make_blobs(centers=5, random_state=42)\n",
    "X[:5, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(X[:, 0], X[:, 1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value of the `random_state` parameter in our `k_means()` function can make a big difference to the final clusters! We might find what are indeed the intuitive clusters in our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = k_means(X[:, 0], X[:, 1], k=5, random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we also might get different results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = k_means(X[:, 0], X[:, 1], k=5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = k_means(X[:, 0], X[:, 1], k=5, random_state=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And of course we could set $k$ to something other than 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = k_means(X[:, 0], X[:, 1], k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## **Assumptions** and **challenges** of $k$-means\n",
    "\n",
    "- Demonstrate the ideal $k$-means dataset\n",
    "- Show three scenarios where $k$-means struggles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ideal $k$-means scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "demo.ideal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Meets all assumptions:\n",
    "\n",
    "- Independent variables\n",
    "- Balanced cluster sizes\n",
    "- Clusters have similar density\n",
    "- Spherical clusters/equal variance of variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Problem Scenario 1 - classes not all round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo.messyOne()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Problem Scenario 2 - imbalanced class size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo.messyTwo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Problem Scenario 3 - class size and density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo.messyThree()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Solution to challenges:\n",
    "\n",
    "- Preprocessing: PCA or scaling\n",
    "- Try a different clustering methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Simple Demonstration\n",
    "\n",
    "- This is a sample dataset. \n",
    "- Let us assume the data is already scaled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_dat = pd.read_csv(\"data/xclara.txt\",\n",
    "                        header=0,\n",
    "                        index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_dat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### EDA of variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_dat.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(dummy_dat['V1'], dummy_dat['V2']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Introduction of `Kmeans`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KMeans(n_clusters=3).fit(dummy_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(dummy_dat['V1'], dummy_dat['V2'])\n",
    "for i in range(len(model.cluster_centers_)):\n",
    "    ax.scatter(model.cluster_centers_[i][0],\n",
    "               model.cluster_centers_[i][1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict([[60, -20]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(dummy_dat['V1'], dummy_dat['V2'],\n",
    "           c=model.labels_);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df = pd.concat([dummy_dat, \n",
    "                        pd.DataFrame(model.labels_, columns=['cluster'])], \n",
    "                       axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster0 = labeled_df[labeled_df['cluster'] == 0]\n",
    "cluster1 = labeled_df[labeled_df['cluster'] == 1]\n",
    "cluster2 = labeled_df[labeled_df['cluster'] == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster0['V1'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(cluster0['V1'], cluster0['V2'], c='k', alpha=0.4)\n",
    "ax.scatter(cluster1['V1'], cluster1['V2'], c='c', alpha=0.4)\n",
    "ax.scatter(cluster2['V1'], cluster2['V2'], c='r', alpha=0.4);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Note\n",
    "#### You *may* have different cluster centers.\n",
    "\n",
    "We saw in the demo that the algorithm is sensitive to starting points. It's a good idea to use `random_state` to ensure repeatable results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Choosing the appropriate number for $k$\n",
    "\n",
    "#### Two metrics we can use: *Elbow Method* and the *Silhouette Coefficient*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Elbow Method\n",
    "\n",
    "Elbow method uses the sum of squared error (SSE) calculated from each instance of $k$ to find the best value of $k$.\n",
    "\n",
    "This is sometimes called the \"inertia\" of the model, and fitted sklearn $k$-means models have an `inertia_` attribute.\n",
    "\n",
    "Sometimes you will see the SSE divided by the total sum of squares in the dataset (how far is each point from the center of the entire dataset)\n",
    "\n",
    "Fewer clusters seems better, but _inertia will always decrease with more clusters_. Hence the idea of looking for an _elbow_ in the plot of inertia vs. $k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.inertia_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inertia is the sum of squared distances between points and their cluster center."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Specifying the dataset and initializing variables\n",
    "X = dummy_dat\n",
    "distortions = []\n",
    "\n",
    "# Calculate inertia for different K\n",
    "for k in range(2, 10):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=301)\n",
    "    kmeans.fit(X)\n",
    "    distortions.append(kmeans.inertia_)\n",
    "\n",
    "# Plot values of inertia\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "ax.set_title('Elbow curve')\n",
    "ax.set_xlabel('k')\n",
    "ax.plot(range(2, 10), distortions)\n",
    "ax.grid(True)\n",
    "ax.set_ylabel(\"Inertia\")\n",
    "ax.set_xlabel(\"Number of Clusters\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many clusters is best?\n",
    "\n",
    "- \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Silhouette Coefficient\n",
    "\n",
    "![silo](images/silo2.png)\n",
    "\n",
    "> **a** refers to the average distance between a point and all other points in that cluster.\n",
    ">\n",
    "> **b** refers to the average distance between that same point and all other points in clusters to which it does not belong\n",
    "\n",
    "It is calculated for each point in the dataset, then averaged across all points for one cumulative score.\n",
    "\n",
    "The Silhouette Coefficient ranges between -1 and 1. The closer to 1, the more clearly defined are the clusters. The closer to -1, the more incorrect assignment.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the labels\n",
    "labels = model.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's score using sklearn's silhouette_score\n",
    "metrics.silhouette_score(dummy_dat, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding silhouette scores for many values of k\n",
    "silhouette_scores = {}\n",
    "\n",
    "for k in range(2, 10):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=301)\n",
    "    kmeans.fit(dummy_dat)\n",
    "    silhouette_scores[k] = metrics.silhouette_score(dummy_dat, kmeans.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "silhouette_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Plot Silhouette coefficient\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "ax.plot(range(2, 10), silhouette_scores.values())\n",
    "ax.axhline(y=np.mean(list(silhouette_scores.values())), color=\"red\", linestyle=\"--\", \n",
    "           label=\"average silhouette score\")\n",
    "\n",
    "ax.set_title('Silhouette coefficients over k')\n",
    "ax.set_xlabel('k')\n",
    "ax.set_ylabel('silhouette coefficient')\n",
    "ax.legend()\n",
    "ax.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From a colleague\n",
    "# This will showcase what each cluster looks like in terms of fit\n",
    "from matplotlib import cm\n",
    "\n",
    "km = KMeans(n_clusters=3, random_state=0)\n",
    "y_km = km.fit_predict(dummy_dat)\n",
    "\n",
    "cluster_labels = np.unique(y_km)\n",
    "n_clusters = cluster_labels.shape[0]\n",
    "silhouette_vals = metrics.silhouette_samples(dummy_dat, y_km, metric='euclidean')\n",
    "y_ax_lower, y_ax_upper = 0, 0\n",
    "yticks = []\n",
    "\n",
    "for i, c in enumerate(cluster_labels):\n",
    "    c_silhouette_vals = silhouette_vals[y_km == c]\n",
    "    c_silhouette_vals.sort()\n",
    "    y_ax_upper += len(c_silhouette_vals)\n",
    "    color = cm.jet(float(i) / n_clusters)\n",
    "    plt.barh(range(y_ax_lower, y_ax_upper), c_silhouette_vals, height=1.0, \n",
    "             edgecolor='none', color=color)\n",
    "\n",
    "    yticks.append((y_ax_lower + y_ax_upper) / 2.)\n",
    "    y_ax_lower += len(c_silhouette_vals)\n",
    "    \n",
    "silhouette_avg = np.mean(silhouette_vals)\n",
    "plt.axvline(silhouette_avg, color=\"red\", linestyle=\"--\") \n",
    "\n",
    "plt.yticks(yticks, cluster_labels + 1)\n",
    "plt.ylabel('Cluster')\n",
    "plt.xlabel('Silhouette coefficient')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering Review:\n",
    "\n",
    "No right answers! Just looking for patterns.\n",
    "\n",
    "Evaluate goodness-of-fit using either elbow scores or silhouette scores.\n",
    "\n",
    "Want elbow score to be low (but not minimum), silhouette score to be high."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Useful Resource!\n",
    "\n",
    "The Yellowbrick library has some of these plots already built out nicely: https://www.scikit-yb.org/en/latest/api/cluster/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exercise:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Using online retail data data from [UCI database](https://archive.ics.uci.edu/ml/datasets/online+retail).\n",
    "\n",
    "You are looking for patterns so you can get people to buy more, more frequently. \n",
    "\n",
    "You'll have to do some cleaning, and you might want to create some new variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shopping = pd.read_csv('data/OnlineRetail.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shopping.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shopping.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Review $k$-means steps\n",
    "1. Look at and clean data (if needed)\n",
    "2. Scale data\n",
    "3. Try various values of $k$\n",
    "4. Plot SSE and Silhouette coefficient to find best $k$\n",
    "5. Describe the characteristics of each cluster using their centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at and clean data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try values for k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore centroids\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### How many clusters fit the data?\n",
    "\n",
    "What can you tell me about them?\n",
    "\n",
    "- \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
