{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Tuning with Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Objectives\n",
    "\n",
    "- Explain what hyperparameters are\n",
    "- Describe the purpose of grid searching\n",
    "- Implement grid searching for the purposes of model optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "![](https://imgs.xkcd.com/comics/machine_learning.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Many of the models we have looked at are really *families* of models in the sense that they make use of **hyperparameters**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Thus for example the $k$-nearest-neighbors algorithm allows us to make:\n",
    "\n",
    "- a 1-nearest-neighbor model\n",
    "- a 2-nearest-neighbors model\n",
    "- a 3-nearest-neighbors model\n",
    "- etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Or, for another example, the decision tree algorithm allows us to make:\n",
    "\n",
    "- a classifier that branches according to information gain\n",
    "- a classifier that branches according to Gini impurity\n",
    "- a regressor that branches according to mean squared error\n",
    "- etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Depending on the sort of problem and data at hand, it is natural to experiment with different values of these hyperparameters to try to improve model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> We can think of these **hyperparameters** as _dials_ of the base model\n",
    "\n",
    "<img src='https://cdn.dribbble.com/users/947489/screenshots/4522230/0001-0128.gif' width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Difference from Parametric / Non-Parametric Models\n",
    "\n",
    "Contrast the notion of hyperparameters with the distinction between **parametric** and **non-parametric** models.\n",
    "\n",
    "A linear regression model is parametric in the sense that we start with a given model *form* and we then search for the optimal parameters to fill in that form. But *those* parameters are not the sort we might tweak for the purposes of improving model performance! On the contrary, there is **one** best set of parameters, and the training of the model is a matter of finding those optimal values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario: Cat in the Dat(a)\n",
    "\n",
    "Let's revisit our cat in the data kaggle competition: https://www.kaggle.com/c/cat-in-the-dat-ii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, StandardScaler\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import roc_auc_score, plot_roc_curve, plot_precision_recall_curve\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab, then explore data\n",
    "df = pd.read_csv(\"data/cat_in_the_dat2_train.csv\", index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our X and y\n",
    "\n",
    "X = df.drop(columns=['target'])\n",
    "y = df['target']\n",
    "\n",
    "# and train test split - to create our val holdout set!\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1,\n",
    "                                                  random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessor Pipeline\n",
    "\n",
    "Let's bring back our preprocessor pipeline we built:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First defining our overall used columns - those with less than 30 uniques\n",
    "used_cols = [col for col in X_train.columns if len(X_train[col].unique()) < 30]\n",
    "\n",
    "# Defining our object columns\n",
    "obj_cols = [col for col in used_cols if X_train[col].dtype == 'O']\n",
    "# And our object transformer\n",
    "obj_transformer = Pipeline(steps=[\n",
    "    (\"obj_imputer\", SimpleImputer(strategy = 'constant', fill_value='WHATEVER')),\n",
    "    ('ohe', OneHotEncoder(drop=['WHATEVER']*len(obj_cols)))\n",
    "])\n",
    "\n",
    "# Now defining our numeric columns\n",
    "num_cols = [col for col in used_cols if X_train[col].dtype != 'O']\n",
    "# And our numeric transformer\n",
    "num_transformer = Pipeline(steps = [\n",
    "    ('num_imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('scaler', MinMaxScaler())\n",
    "])\n",
    "\n",
    "# Putting them together into a preprocessor\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    (\"num_trans\", num_transformer, num_cols),\n",
    "    ('obj_trans', obj_transformer, obj_cols)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Trying Different Models & Values\n",
    "\n",
    "Let's explore three different model types, using our preprocessor pipeline and evaluating using `cross_validate`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your Choice: KNN or Naive Bayes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Automatically Searching for Optimal Hyperparameters with Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "It's not a bad idea to experiment with the values of your models' hyperparameters a bit as you're getting a feel for your models' performance. But there are more systematic ways of going about the search for optimal hyperparameters. One method of hyperparameter tuning is **grid searching**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The idea is to build multiple models with different hyperparameter values and then see which one performs the best. The hyperparameters and the values to try form a sort of *grid* along which we are looking for the best performance. \n",
    "\n",
    "For example, for KNN:\n",
    "\n",
    "    n_neighbors | metric      | weights\n",
    "    ______________________________________\n",
    "    1           | 'minkowski' | 'uniform'\n",
    "    3           | 'manhattan' | 'distance'\n",
    "    5           |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Scikit-Learn has a [`GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) class whose `fit()` method runs this procedure. Note that this can be quite computationally expensive since:\n",
    "\n",
    "- A model is constructed for each combination of hyperparameter values that we input; and\n",
    "- Each model is cross-validated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### `GridSearchCV`\n",
    "\n",
    "Note! When using `GridSearchCV` in SKLearn with a pipeline, you need to use the nicknames we give to tell it where these hyperparameters are being tested!\n",
    "\n",
    "Resource: https://scikit-learn.org/stable/tutorial/statistical_inference/putting_together.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose one model type to optimize, and set up the base pipeline\n",
    "\n",
    "clf = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T03:33:34.611150Z",
     "start_time": "2021-10-28T03:33:34.608300Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Define the parameter grid for one model type\n",
    "\n",
    "param_grid = {\n",
    "    None\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Question: How many models will we be constructing with this grid?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T03:33:35.802959Z",
     "start_time": "2021-10-28T03:33:35.800647Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Initialize the grid search object with five-fold cross-validation\n",
    "\n",
    "gs = None\n",
    "\n",
    "# Then fit it to our X_train and y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T03:33:38.438408Z",
     "start_time": "2021-10-28T03:33:38.435309Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Check out the best parameters\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T03:33:38.739396Z",
     "start_time": "2021-10-28T03:33:38.736044Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Check out the best score\n",
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T03:33:40.999187Z",
     "start_time": "2021-10-28T03:33:40.984761Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We can grab the best estimator out, as a fit model!\n",
    "gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T03:33:41.214030Z",
     "start_time": "2021-10-28T03:33:41.205532Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# A bigger picture of our results\n",
    "gs.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T03:33:41.818645Z",
     "start_time": "2021-10-28T03:33:41.790982Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Which we can throw into a dataframe if we like\n",
    "pd.DataFrame(gs.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Choice of Grid Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Which values should you pick for your grid? Intuitively, you should try both \"large\" and \"small\" values, but of course what counts as large and small will really depend on the type of hyperparameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- For a k-nearest neighbors model, 1 or 3 would be a small value for the number of neighbors and 15 or 17 would be a large value.\n",
    "- For a decision tree model, what counts as a small `max_depth` will really depend on the size of your training data. A `max_depth` of 5 would likely have little effect on a very small dataset but, at the same time, it would probably significantly decrease the variance of a model where the dataset is large.\n",
    "- For a logistic regression's regularization constant, you may want to try a set of values that are exponentially separated, like \\[1, 10, 100, 1000\\].\n",
    "- **If a grid search finds optimal values at the ends of your hyperparameter ranges, you might try another grid search with more extreme values.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Do a grid search on a different model type! What are the optimal values for the hyperparameters you've chosen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Level Up: Random Searching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "It is also possible to search for good hyperparameter values randomly. This is a nice choice if computation time is an issue or if you are tuning over continuous hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### `RandomizedSearchCV` with `LogisticRegression`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T03:34:46.731177Z",
     "start_time": "2021-10-28T03:34:46.727225Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "log_reg_grid = {'C': stats.uniform(loc=0, scale=10),\n",
    "               'l1_ratio': stats.expon(scale=0.2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T03:34:49.166819Z",
     "start_time": "2021-10-28T03:34:48.678224Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rs = RandomizedSearchCV(estimator=LogisticRegression(penalty='elasticnet',\n",
    "                                                    solver='saga',\n",
    "                                                    max_iter=1000,\n",
    "                                                    random_state=42),\n",
    "                        param_distributions=log_reg_grid,\n",
    "                        random_state=42)\n",
    "\n",
    "rs.fit(X_train, y_train)\n",
    "\n",
    "rs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Level Up: More Grid Search Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Use a classifier of your choice to predict the category of price range for the phones in this dataset. Try tuning some hyperparameters using a grid search, and then write up a short paragraph about your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T03:34:38.974212Z",
     "start_time": "2021-10-28T03:34:38.957557Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "phones_train = pd.read_csv('data/phone-train.csv')\n",
    "phones_test = pd.read_csv('data/phone-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "TOC",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "232px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
