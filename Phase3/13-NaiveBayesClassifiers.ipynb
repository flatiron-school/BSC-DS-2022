{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Objectives\n",
    "\n",
    "- Describe how Bayes's Theorem can be used to make predictions of a target\n",
    "- Identify the appropriate variant of Naive Bayes models for a particular business problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bringing Back Bayes\n",
    "\n",
    "> \"Naive Bayes classifiers are linear classifiers that are known for being **simple yet very efficient**. The probabilistic model of naive Bayes classifiers is based on Bayesâ€™ theorem, and the adjective naive comes from the assumption that the features in a dataset are **mutually independent**. In practice, the independence assumption is often violated, but naive Bayes classifiers **still tend to perform very well** under this unrealistic assumption. Especially for small sample sizes, naive Bayes classifiers can outperform the more powerful alternatives.\"\n",
    "\n",
    "[Source: Sebasitian Raschka: Naive Bayes and Text Classification](https://sebastianraschka.com/Articles/2014_naive_bayes_1.html) (emphasis is mine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revisiting the theorem itself:\n",
    "\n",
    "![breaking down the function behind naive bayes](images/naive_bayes_icon.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's introduce how we'll use it as a classifier!\n",
    "\n",
    "<img src=\"images/another_one.png\" width=750 alt=\"further breakdown of the pieces of naive bayes\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how, when we move from the pure Bayes theorem to just comparing ratios, we effectively abstract away $P(\\text{features})$! That actually simplifies our work - rather than calculating the exact probability for each label given the features, all we need to do is compare relative numerators to know which label (or target class) is more likely! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Explore:\n",
    "\n",
    "First, let's walk through [Chris Albon's description of Naive Bayes Classifiers from Scratch!](https://chrisalbon.com/code/machine_learning/naive_bayes/naive_bayes_classifier_from_scratch/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our First Scenario: Spam Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Spam, Spam, Spam, Spam, Spam..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<img src=\"images/wall_of_spam.jpeg\" alt=\"Many cans of spam\" width=600>\n",
    "\n",
    "> This is the classic example: detecting email spam!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**The Problem Setup**\n",
    "\n",
    "> We get emails that can be either emails we care about (***ham*** ðŸ·) or emails we don't care about (***spam*** ðŸ¥«). \n",
    ">\n",
    "> We can probably look at the words in the email and get an idea of whether they are spam or not just by observing if they contain red-flag words ðŸš©\n",
    "> \n",
    "> We won't always be right, but if we see an email that uses word(s) that are more often associated with spam, then we can feel more confident as labeling that email as spam!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Naive Bayes Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "What we gotta do:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "1. Look at spam and not spam (ham) emails\n",
    "2. Identify words that suggest classification\n",
    "3. Determine probability that words occur in each classification\n",
    "4. Profit! (aka classify new emails as \"spam\" or \"ham\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### What's So Great About This?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- We can keep updating our belief based on the emails we detect as we learn more\n",
    "- Relatively simple\n",
    "- Can expand to multiple words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## The Naive Assumption"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "$P(A,B) = P(A\\cap B) = P(A)\\ P(B)$ only if independent \n",
    "\n",
    "In practice, makes sense & is usually pretty good assumption"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## The Formula"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "I explored our training emails, and found that the word \"cash\" is used a lot more in spam emails than 'ham' emails.\n",
    "\n",
    "In Bayesian terms:\n",
    "\n",
    "$$ P(ðŸ¥« | \\text{\"cash\"}) = \\frac{P(\\text{\"cash\"} | ðŸ¥«) * P(ðŸ¥«)}{P(\\text{\"cash\"})}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### What Parts Can We Find?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- $P(\\text{\"cash\"})$\n",
    "    * That's just the probability of finding the word \"cash\", aka the frequency of the word\n",
    "- $P(ðŸ¥«)$\n",
    "    * Our *prior knowledge*: the frequency of spam emails\n",
    "- $P(\\text{\"cash\"} | ðŸ¥«)$\n",
    "    * How frequently \"cash\" is used in known spam emails. Count the frequency across all spam emails\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Calculating the Probability That Our Email Is Spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# From my exploration of emails, I found about 8% have the word 'cash'\n",
    "p_cash = 0.0849\n",
    "\n",
    "# Of our emails, about 33% were spam\n",
    "p_spam = 0.327122\n",
    "\n",
    "# 24% of all spam emails have the word \"cash\"\n",
    "p_cash_given_its_spam = 0.2379"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Calculate our posterior!\n",
    "p_spam_given_cash = None\n",
    "\n",
    "print(f'If the email has the word \"cash\" in it, there is a \\\n",
    "{p_spam_given_cash*100}% chance the email is spam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**DISCUSS**: Does this make sense?\n",
    "\n",
    "Suppose I had 250 total emails.\n",
    "\n",
    "- How many total emails should I expect to have the word 'cash' in them?\n",
    "\n",
    "    - \n",
    "    \n",
    "    \n",
    "- How many should I expect to be spam?\n",
    "\n",
    "    - \n",
    "    \n",
    "    \n",
    "- How many of the spam emails should I expect to have the word 'cash' in them?\n",
    "\n",
    "    - \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This appears to work fairly well in our given context (which, for the record, was [built off real email data found on Kaggle!](https://www.kaggle.com/datasets/chandramoulinaidu/spam-classification-for-basic-nlp)) \n",
    "\n",
    "#### Expanding Our Evidence:\n",
    "\n",
    "Of course, as we already saw in Chris Albon's description/walkthrough above - we can break out beyond just one word, and use many different data points which we (naively) assume are independent from each other! In this example, we could use not just 'cash' but also 'buy', 'free', 'act now' etc etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using SKLearn\n",
    "\n",
    "\n",
    "### New Scenario:\n",
    "\n",
    "Suppose we are using an API to gather articles from a news website and grabbing phrases from two different types of articles: on **sports** and on **politics**.\n",
    "\n",
    "Is there a way we can use machine learning to help us label the articles quickly?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayes in the context of our problem:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### $$ P(politics | \\text{article text}) = \\frac{P(\\text{article text}|politics) * P(politics)}{P(\\text{article text})}$$\n",
    "\n",
    "Where *article* is our piece to be classified, which will be fed into the classifier as a breakdown of words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How should we calculate $ P(politics) $ ?\n",
    "\n",
    "This is essentially the distribution of the probability of either type of article. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How should we calculate $ P(\\text{article text} | politics) $ ?\n",
    "\n",
    "These are the *likelihoods*, and:\n",
    "\n",
    "- If the relevant features are **categorical**, we can simply count the numbers of each category in the dataset. For example, if the features are whether the article relates to sports or politics, then, to calculate the likelihoods, we'll just count how words show up in the sports versus politics articles.\n",
    "- If the relevant features are **numerical**, we'll have to do something else. A good way of proceeding is to rely on (presumed) underlying distributions of the data. [Here](https://medium.com/analytics-vidhya/use-naive-bayes-algorithm-for-categorical-and-numerical-data-classification-935d90ab273f) is an example of using the normal distribution to calculate likelihoods\n",
    "\n",
    "Regardless, in our case, we need to break the phrases down into individual words:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $$ P(\\text{article text} | politics) = \\prod_{i=1}^{d} P(\\text{word}_{i} | politics) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We need to make a *Naive* assumption!\n",
    "\n",
    "- assuming independence for each word\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'd assume something like:\n",
    "\n",
    "#### $$ P(\\text{word}_{i} | politics) = \\frac{\\text{# of word}_{i} \\text{ in politics articles}}{\\text{# of total words in politics articles}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BUT! Can you foresee any issues with this?\n",
    "\n",
    "- we can't have a probability of 0, which would happen if the model encounters a word it's never seen before\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enter: Laplace Smoothing\n",
    "\n",
    "#### $$ P(\\text{word}_{i} | politics) = \\frac{\\text{# of word}_{i} \\text{ in politics articles} + \\alpha} {\\text{# of total words in politics articles} + \\alpha d} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This correction process is called Laplace Smoothing:\n",
    "\n",
    "- d : number of features (in this instance total number of vocabulary words)\n",
    "- $\\alpha$ can be any number greater than 0 (it is usually 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our First Text Classification with Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, f1_score, plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetching our data\n",
    "news_train = fetch_20newsgroups(subset='train', \n",
    "                                categories = ['rec.sport.baseball', \n",
    "                                              'talk.politics.misc'])\n",
    "news_test = fetch_20newsgroups(subset='test', \n",
    "                               categories = ['rec.sport.baseball', \n",
    "                                              'talk.politics.misc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collecting data in dataframe\n",
    "df_train = pd.DataFrame()\n",
    "df_train['Data'] = news_train.data\n",
    "df_train['Target'] = news_train.target\n",
    "\n",
    "df_test = pd.DataFrame()\n",
    "df_test['Data'] = news_test.data\n",
    "df_test['Target'] = news_test.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grabbing our target classes so we know which is which\n",
    "target_classes = dict(enumerate(news_test.target_names))\n",
    "target_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.info()\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Train Target Ratio: {df_train[\"Target\"].mean():.4f}')\n",
    "print(f'Train Target Ratio: {df_test[\"Target\"].mean():.4f}')\n",
    "# roughly equivalent breakdowns between classes in train and test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Need to turn our text data into numbers..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a Count Vectorizer\n",
    "# Goes through each doc and counts how many of each word\n",
    "vectorizer = CountVectorizer()\n",
    "# Fitting and transforming our train data\n",
    "X_train = vectorizer.fit_transform(df_train['Data']).toarray() # to array is just for the model later\n",
    "# Just transforming our test data\n",
    "X_test = vectorizer.transform(df_test['Data']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What does this look like?\n",
    "X_train_vectorized = pd.DataFrame(X_train, columns=vectorizer.get_feature_names())\n",
    "X_train_vectorized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's explore a single example of our new vectorized X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before\n",
    "df_train.iloc[[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full text before\n",
    "df_train['Data'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After\n",
    "X_train_vectorized.iloc[0].sort_values(ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now time to model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting our y values\n",
    "y_train = df_train['Target']\n",
    "y_test = df_test['Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating our model - just using default values\n",
    "model = MultinomialNB()\n",
    "# Fitting our model\n",
    "model.fit(X_train,y_train)\n",
    "# Making predictions \n",
    "train_preds = model.predict(X_train)\n",
    "y_preds = model.predict(X_test)\n",
    "\n",
    "# How'd we do?\n",
    "print(f'Logistic Regression Train Accuracy: {accuracy_score(y_train, train_preds):.4f}')\n",
    "print(f'Naive Bayes Test Accuracy: {accuracy_score(y_test, y_preds):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(model, X_test, y_test, display_labels = target_classes.values())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for comparison...\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Instantiating our model - just using default values\n",
    "logreg = LogisticRegression(random_state=123)\n",
    "# Fitting our model\n",
    "logreg.fit(X_train,y_train)\n",
    "# Making predictions \n",
    "train_preds_lr = logreg.predict(X_train)\n",
    "y_preds_lr = logreg.predict(X_test)\n",
    "\n",
    "# How'd we do?\n",
    "print(f'Logistic Regression Train Accuracy: {accuracy_score(y_train, train_preds_lr):.4f}')\n",
    "print(f'Logistic Regression Test Accuracy: {accuracy_score(y_test, y_preds_lr):.4f}')\n",
    "\n",
    "plot_confusion_matrix(logreg, X_test, y_test, display_labels = target_classes.values())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different Naive Bayes Classifiers in SKLearn\n",
    "\n",
    "AKA why'd we choose `MultinomialNB` above?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes\n",
    "\n",
    "[Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html)\n",
    "\n",
    "> \"The multinomial Naive Bayes classifier is suitable for classification with discrete features (e.g., word counts for text classification).\"\n",
    ">\n",
    "> -- SKLearn's Documentation page linked above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes\n",
    "\n",
    "[Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html)\n",
    "\n",
    "<img src=\"https://chrisalbon.com/images/machine_learning_flashcards/Gaussian_Naive_Bayes_Classifier_print.png\" alt=\"Gaussian NB flashcard from Chris Albon\" width=600>\n",
    "\n",
    "> \"Because of the assumption of the normal distribution, Gaussian Naive Bayes is best used in cases when all our features are continuous.\"\n",
    ">\n",
    "> -- [Chris Albon](https://chrisalbon.com/code/machine_learning/naive_bayes/gaussian_naive_bayes_classifier/) (also the source of the flashcard image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Others\n",
    "\n",
    "SKLearn has also built out classes for [Complement Naive Bayes](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.ComplementNB.html) (good for imbalanced datasets), [Bernoulli Naive Bayes](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.BernoulliNB.html) (designed for binary/boolean input features), and [Categorical Naive Bayes](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.CategoricalNB.html) (good for discrete features that are categorically distributed) - check them out!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    ">\"In spite of their apparently over-simplified assumptions, naive Bayes classifiers have worked quite well in many real-world situations, famously document classification and spam filtering. They require a small amount of training data to estimate the necessary parameters.\" \n",
    ">\n",
    "> -- [SKLearn User Guide on Naive Bayes](https://scikit-learn.org/stable/modules/naive_bayes.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pros:\n",
    "\n",
    "* It is an efficient way to predict class of test data set\n",
    "* It perform well in multi class prediction\n",
    "* When assumption of independence holds, a Naive Bayes classifier performs requires less training data and can perform better than models like logistic regression\n",
    "* Works very well on a large number of input features (doesn't suffer from the same curse of dimensionality)\n",
    "* Performs better with categorical inputs. For numerical input, one has to assume a normal distribution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cons:\n",
    "\n",
    "* Naive Bayes is also known as a bad estimator, so the probability outputs from `predict_proba` are not to be taken seriously\n",
    "* We are assuming of independent predictors, but in real life, it is almost impossible that we get a set of predictors which are completely independent (amazingly, still works a lot of the time though!)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "TOC",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "221px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
