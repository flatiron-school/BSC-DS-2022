{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Power, Analysis of Variance, and Chi-Squared Goodness of Fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "- Recognize how power analysis sets up hypothesis tests\n",
    "- Understand the issues of multiple comparisons\n",
    "- Compare and contrast t-tests with ANOVA\n",
    "- Implement ANOVA in Python\n",
    "- Understand how the Ï‡2-statistic and tests are similar to other hypothesis tests (t-test, ANOVA, etc.)\n",
    "- Calculate the Ï‡2-statistic\n",
    "- Perform a Ï‡2 goodness-of-fit test\n",
    "- Perform a Ï‡2 test for independence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-07T20:37:20.194588Z",
     "start_time": "2020-08-07T20:37:19.088892Z"
    }
   },
   "outputs": [],
   "source": [
    "# Overall Imports\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "np.random.seed(10)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Power Analysis\n",
    "\n",
    "Running a power analysis allows you to estimate the minimum sample size required in order to find some minimum effect size, while setting your tolerance for both Type 1 and Type 2 Errors.\n",
    "\n",
    "That's right - there's a relationship between your experiment's sample size, your significance level ($\\alpha$), your statistical power ($1-\\beta$), and the effect size you'd be able to measure with such a hypothesis test!\n",
    "\n",
    "[Useful Resource: Machine Learning Mastery's Gentle Introduction to Statistical Power and Power Analysis in Python](https://machinelearningmastery.com/statistical-power-and-power-analysis-in-python/)\n",
    "\n",
    "\n",
    "Let's break down some of those pieces that we haven't discussed as much:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Power\n",
    "\n",
    "At its core, the statistical power of a test is simply $1 - \\beta$, where $\\beta$ is the chance of making a Type II Error.\n",
    "\n",
    "<img src=\"images/confusionmatrix.png\" alt=\"type 1 and type 2 errors in a confusion matrix chart\" width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistical power captures the likelihood that you'll find what you're looking for - so it makes sense that you'll only run a test if it's likely you'll find results. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Effect Size\n",
    "\n",
    "Effect size is used to quantify the size of the difference between two groups under observation. Effect sizes are easy to calculate, understand and apply to any measured outcome and is applicable to a multitude of study domains. It is highly valuable towards quantifying the effectiveness of a particular intervention, relative to some comparison. Measuring effect size allows scientists to go beyond the obvious and simplistic, 'Does it work or not?' to the far more sophisticated, 'How well does it work in a range of contexts?'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Where does gender have a larger effect?\n",
    "\n",
    "![gender effect size in seals vs pugs](images/gendereffectsize.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Specifically, knowing the effect size helps you with:\n",
    "\n",
    "- Communicate practical significance of results: an effect might be statistically significant, but does it matter in practical scenarios?\n",
    "\n",
    "- Draw Meta-Analytical conclusions. This allows you to group together a number of existing studies, calculate the meta-analytic effect size and get the best estimate of the effect size of the population\n",
    "\n",
    "- Perform a Power Analysis (aka why we're talking about this right now!), which help determine the number of participants (sample size) that a study would require to achieve a certain probability of finding a true effect - if there is one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Cohen's $d$, standardized metric for effect size\n",
    "\n",
    "Cohenâ€™s $d$ is one of the most common ways to measure effect size. As an effect size, Cohen's d is typically used to represent the magnitude of differences between two (or more) groups on a given variable, with larger values representing a greater differentiation between the two groups on that variable.\n",
    "\n",
    "$$ d = \\frac{\\text{effect size (difference of means)}}{\\text{pooled standard deviation}} $$\n",
    "\n",
    "Here's a formula to calculate it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def Cohen_d(group1, group2):\n",
    "    '''\n",
    "    Compute Cohen's d\n",
    "\n",
    "    group1: Series or NumPy array\n",
    "    group2: Series or NumPy array\n",
    "\n",
    "    returns: float, for Cohen's d \n",
    "    '''\n",
    "\n",
    "    diff = group1.mean() - group2.mean()\n",
    "\n",
    "    n1 = len(group1)\n",
    "    n2 = len(group2)\n",
    "    var1 = group1.var()\n",
    "    var2 = group2.var()\n",
    "\n",
    "    # Calculate the pooled variance\n",
    "    pooled_var = (n1 * var1 + n2 * var2) / (n1 + n2 - 2)\n",
    "    \n",
    "    # Calculate Cohen's d statistic\n",
    "    d = diff / np.sqrt(pooled_var)\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Evaluating Effect Size\n",
    "\n",
    "[good demo here](https://rpsychologist.com/d3/cohend/)\n",
    "\n",
    "In general:\n",
    "\n",
    "- Small effect = 0.2\n",
    "- Medium Effect = 0.5\n",
    "- Large Effect = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Signifiance Level $\\alpha$ (A Recap)\n",
    "\n",
    "When conducting hypothesis testing, we __choose__ a value for alpha, which represents the margin of Type 1 Error we are allowing. Remember, alpha represents the probability in which we are allowed to take the risk of falsely rejecting the null hypothesis. By convention, we set the alpha at 0.05, which we can interpret as \"5% of the time, we are willing to reject the null hypothesis when it is in fact true\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Tie it all back together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "How does sample size affect power?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Well, let's find out!\n",
    "from statsmodels.stats.power import TTestIndPower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,6))\n",
    "ax = fig.add_subplot(2,1,1)\n",
    "fig = TTestIndPower().plot_power(dep_var='nobs',\n",
    "                                 nobs= np.arange(2, 200),\n",
    "                                 effect_size=np.array([0.2, 0.5, 0.8]),\n",
    "                                 alpha=0.01,\n",
    "                                 ax=ax, title='Power of t-Test' + '\\n' + r'$\\alpha = 0.01$')\n",
    "ax.get_legend().remove()\n",
    "ax = fig.add_subplot(2,1,2)\n",
    "fig = TTestIndPower().plot_power(dep_var='nobs',\n",
    "                                 nobs= np.arange(2, 200),\n",
    "                                 effect_size=np.array([0.2, 0.5, 0.8]),\n",
    "                                 alpha=0.05,\n",
    "                                 ax=ax, title=r'$\\alpha = 0.05$') \n",
    "plt.tight_layout()\n",
    "plt.legend(loc=(1.05,2.2));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Elements that affect Statistical Power (chance of Type 2 Error):\n",
    "- Effect Size\n",
    "- Sample Size\n",
    "- Alpha (chance of Type 1 Error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Quick Case Study \n",
    "\n",
    "Suppose you are launching a pilot study with Instagram and you want to examine the new feature (making the heart when you \"like\" someone's photo red instead of white) developed by the frontend engineer attracted more likes __given__ other variables are being held constant. You have collected two datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "experiment = pd.read_csv('data/ig_experiment.csv', index_col=0)\n",
    "control = pd.read_csv('data/ig_control.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "experiment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "control.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Solve for sample size\n",
    "\n",
    "We can use `power_analysis.solve_power` from `statsmodels` to find the sample size you need.\n",
    "\n",
    "[documentation here](https://www.statsmodels.org/dev/generated/statsmodels.stats.power.tt_ind_solve_power.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "effect_size = Cohen_d(control['Likes_Given_Con'], experiment['Likes_Given_Exp'])\n",
    "effect_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# before we even start the experiment, we want to know in order to attain a power of .8 \n",
    "# given an alpha of .05, how many observations we need \n",
    "alpha = 0.05 # significance level\n",
    "power = 0.8\n",
    "\n",
    "power_analysis = TTestIndPower() # Instantiating!\n",
    "sample_size = power_analysis.solve_power(effect_size = effect_size, \n",
    "                                         power = power, \n",
    "                                         alpha = alpha)\n",
    "sample_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More Statistical Tests\n",
    "\n",
    "We've seen that hypothesis tests generally follow this pattern:\n",
    "\n",
    "$$ \\huge \\frac{\\text{Observed difference} - \\text{Expectation if } H_0 \\text{ is true}}{\\text{Average Variance}}$$\n",
    "\n",
    "Let's explore two more statistical tests that are used in other cases, going beyond z-tests and t-tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANOVA \n",
    "\n",
    "ANOVA, short for **An**alysis **o**f **Va**riance, is a commonly used statistical method for comparing means using the calculated F-statistic of 3 groups or more.  \n",
    "\n",
    "<img src='images/rsz_anova-800x444.jpg'>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T-Test or ANOVA?\n",
    "\n",
    "Suppose we want to compare whether multiple groups differ in some type of measures. For example, we have collected mood data grouped by four types of weather - sunny, raining, overcast, or snowy, and we want to find out whether there is a difference in mood across different weather. What tests would you use?\n",
    "\n",
    "A natural reaction would be to conduct multiple t-tests. However, that comes with many drawbacks. First, you would need $\\frac{n(n-1)}{2}$ t tests, which come out to 6 tests. Having more tests meaning you create a higher chance of making type I errors. In this case, our original probability of making type I error grew from 5% to 5% x 6 = 30%! By conduct 6 tests and comparing their mean to each other, we are running a huge risk of believing in false positives. \n",
    "\n",
    "How then, can we combat this? **ANOVA**!\n",
    "\n",
    "Instead of looking at each individual difference, ANOVA examines the ratio of variance between groups, and variance within groups, and find out whether the ratio is big enough to be statistically significant. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T-Test Statistics\n",
    "\n",
    "## $$t = \\frac{x\\bar - \\mu}{\\frac{s}{\\sqrt n}}$$\n",
    "\n",
    "### ANOVA - the F test\n",
    "\n",
    "## $$F = \\frac{MS_{between}}{MS_{within}}$$\n",
    "\n",
    "We can also say that a t-test is a special case of ANOVA, in that we are comparing the means of only two groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the f-statistic? \n",
    "\n",
    "<img src='images/f-stat.png'>\n",
    "    \n",
    "The test statistic for ANOVA follows the F-distribution, a continuous probability function with 2 unique values, the degrees of freedom of groups and the degrees of freedom of all subjects. It is positively skewed and defined only for positive values. \n",
    "\n",
    "If, a = number of groups AND N = total number of subjects THEN \n",
    "    \n",
    "- Degrees of freedom numerator = a - 1\n",
    "- Degrees of freedom denominator = N - a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-07T20:49:51.935817Z",
     "start_time": "2020-08-07T20:49:51.793837Z"
    }
   },
   "outputs": [],
   "source": [
    "# here's one example\n",
    "x = np.linspace(0,5,1000)\n",
    "y = stats.f.pdf(x,3,36) # F distribution!\n",
    "plt.plot(x,y)\n",
    "plt.title('F-distribution dfn=3,dfd=36')\n",
    "plt.xlabel('F-statistic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like all tests, we calculate a test statistic (here, F-ratio or F-statistic) that we can then translate into a p-value to compare with the critical value\n",
    "    \n",
    "If your data is array-like:\n",
    "\n",
    "```python\n",
    "stats.f_oneway(group1, group2, group3) # Note - can pass as many groups as you like!\n",
    "```\n",
    "\n",
    "(note that this is a one way ANOVA... which is the only version we're going to talk about!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's look at an example\n",
    "\n",
    "A company is wondering how they can best optimize the performance of their data scientists. They devise an experiment to test the effect of various substances on the quality of work completed by their data scientists. They come up with four groups:\n",
    "\n",
    "      Group A:  Given 150mg of caffeine\n",
    "      Group B:  Given 2 ounces of alcohol\n",
    "      Group C:  Given 100g of chocolate\n",
    "      Group D:  Given 10 ounces of water\n",
    "After ingesting their given substance, each data scientist was then given the same assessment. After two hours, the accuracy of each data scientist's model was evaluated and recorded and the results are shown below. With a confidence level of 95%, is there a difference in performance across the groups?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-07T20:37:42.397555Z",
     "start_time": "2020-08-07T20:37:42.394075Z"
    }
   },
   "outputs": [],
   "source": [
    "A = [0.92, 0.89, 0.94, 0.91, 0.79, 0.90, 0.96, 0.94, 0.92, 0.85]\n",
    "B = [0.65, 0.79, 0.99, 0.48, 0.54, 0.68, 0.52, 0.49, 0.52, 0.56]\n",
    "C = [0.85, 0.89, 0.91, 0.92, 0.86, 0.82, 0.94, 0.90, 0.91, 0.95]\n",
    "D = [0.69, 0.75, 0.85, 0.74, 0.76, 0.85, 0.78, 0.72, 0.84, 0.86]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-07T20:38:16.687078Z",
     "start_time": "2020-08-07T20:38:16.683139Z"
    }
   },
   "outputs": [],
   "source": [
    "f_stat,p_value = stats.f_oneway(A,B,C,D)\n",
    "print('F-stat:',f_stat)\n",
    "print('p-value:',p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another Example!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/bikeshare_day.csv')\n",
    "data.head()\n",
    "# cnt is the outcome we are trying to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping the season names onto the data\n",
    "seasons = {1: 'spring',\n",
    "           2: 'summer',\n",
    "           3: 'fall',\n",
    "           4: 'winter'}\n",
    "data['season_cat'] = data.season.map(seasons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# boxplot\n",
    "sns.boxplot(x='season_cat', y='cnt', data=data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spring = data.loc[data['season'] == 1]['cnt']\n",
    "summer = data.loc[data['season'] == 2]['cnt']\n",
    "fall = data.loc[data['season'] == 3]['cnt']\n",
    "winter = data.loc[data['season'] == 4]['cnt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_stat,p_value = stats.f_oneway(spring,summer,fall,winter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('F-stat:',f_stat)\n",
    "print('p-value:',p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## A New Class: Non-Parametric Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "So far with $z$-tests, $t$-tests, and $F$-tests (ANOVA) we've been using the mean $\\mu$ and standard deviation $\\sigma$ to address a question. These are all *parametric tests* (use parameters to describe the null hypothesis)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "But imagine if we had something like I asked 50 men and 50 women if they preferred pizza (ðŸ•) or pasta (ðŸ)\n",
    "\n",
    "|     |  ðŸ• | ðŸ  |\n",
    "| --- | --- | --- |\n",
    "|  â™€  | 31  | 19  |\n",
    "|  â™‚  | 28  | 22  |\n",
    "\n",
    "We really couldn't say something about the average favorite food. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Instead, we tend to talk about proportions or frequencies to describe the data. This is where *non-parametric tests* can come in handy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# The $\\chi^2$ Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "When we talk about categorical variables vs other categorical variables (compared to continuous variables), the $\\chi^2$ test is a good fit for our test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "There are a few different $\\chi^2$ tests but they all center around the **$\\chi^2$ statistic** and the [**$\\chi^2$ distribution**](https://en.wikipedia.org/wiki/Chi-square_distribution)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/2/21/Chi-square_distributionPDF.png/640px-Chi-square_distributionPDF.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The number of degrees of freedom for the $\\chi^2$ distribution is $k$-1, where $k$ is the number of groups. For the $\\chi^2$ distribution $k$ is also the *mean* of the distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dist = stats.chi2(1)\n",
    "dist.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "x = np.linspace(dist.ppf(0.1), dist.ppf(0.9), 100)\n",
    "y = dist.pdf(x)\n",
    "\n",
    "ax.plot(x, y)\n",
    "ax.set_title('$\\chi^2$ pdf, k=1');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Going back to our pizza vs pasta example, let's imagine we ask 100 individuals about their preference:\n",
    "\n",
    "\n",
    "|                  |  ðŸ• | ðŸ  |\n",
    "| ---------------- | --- | --- |\n",
    "| **OBSERVATIONS** | 52  | 48  |\n",
    "\n",
    "\n",
    "It's not necessarily obvious if there is a _statistically_ significant difference in preference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "There are actually different $\\chi^2$ hypothesis tests and they have different use cases but all surround observing different categories from different groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# $\\chi^2$ Goodness-of-Fit Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> If we are looking to see if some observed proportion _matches_ an expected proportion in relation to one variable, we do a **$\\chi^2$ goodness-of-fit test**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The steps follow like this:\n",
    "\n",
    "1. Start with your _observation_ frequencies/proportions for each group\n",
    "2. State what your _expectations_ were for each group\n",
    "3. Check your assumptions (no expected frequency $\\lt 5$)\n",
    "4. Calculate the $\\chi^2$ statistic\n",
    "5. Determine your p-value via your $\\chi^2$ statistic and degrees of freedom using the $\\chi^2$ distribution\n",
    "6. Interpret!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's try out an example as we work out how this test works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Suppose a company has hired us on. The company has been running a website in the U.S. but is now expanding it to other countries, namely the U.K. They would like to know if the U.K. users are \"typical\" in comparison to U.S. users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "They tell us that at the beginning of signing up with the site, the users can choose one of four types of profiles: **A**, **B**, **C**, & **D**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "There was an experiment run by the company where $400$ U.K. users were given early access to the platform. Their choice in profiles were the following:\n",
    "\n",
    "|              |  A  |  B  |  C  |  D  |\n",
    "| ------------ | --- | --- | --- | --- |\n",
    "| **UK USERS** | 50  | 100 | 180 | 70  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Expected Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now to determine if these U.K users are similar to U.S. users, we need to know what profile types  the U.S. users choose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Suppose we have historical data on U.S. users and know:\n",
    "\n",
    "- **A** is chosen $15\\%$ of the time\n",
    "- **B** is chosen $20\\%$ of the time\n",
    "- **C** is chosen $45\\%$ of the time\n",
    "- **D** is chosen $20\\%$ of the time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Then we would _expect_ that the $400$ U.K. users would follow the same pattern. Note this assumes the $H_0$ (there is no difference between U.K. & U.S. users). \n",
    "\n",
    "Thus we get the following expectations:\n",
    "\n",
    "|              |  A  |  B  |  C  |  D  |\n",
    "| ------------ | --- | --- | --- | --- |\n",
    "| **EXPECTED** | 60  | 80  | 180 | 80  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "To make life easier for us, let's combine this into one table:\n",
    "\n",
    "|              |  A  |  B  |  C  |  D  |\n",
    "| ------------ | --- | --- | --- | --- |\n",
    "| **UK USERS** | 50  | 100 | 180 | 70  |\n",
    "| **EXPECTED** | 60  | 80  | 180 | 80  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## No Expected Frequency $\\lt 5$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Quickly, we should note that if any of the expected frequency is less than $5$ the $\\chi^2$ test can have some issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Technically, this is arbitrary (like many of our limits in statistics) but is generally a good rule of thumb."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In this case, we see no expected frequency falls under $5$ so we're good to proceed! ðŸ‘ðŸ¼"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Calculate $\\chi^2$ Statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now we want to determine our test statistic. Recall what we want in a statistic:\n",
    "\n",
    "$$ \\large \\frac{\\text{Observed difference} - \\text{Expectation if } H_0 \\text{ is true}}{\\text{Average Variance}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Remember, we really want to capture the observed difference from what we'd expect. But if we did this and summed theses differences we'd always get $0$. So instead we square the differences before adding them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We still need to scale these differences and we naturally use the expectation value for each group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This gives us the $\\chi^2$ statistic:\n",
    "\n",
    "\n",
    "$$\\large \\chi^2 = \\sum \\frac{( Expected_i - Observed_i)^2}{Expected_i}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "So back to our example, we'll use our table to organize the values:\n",
    "\n",
    "|                     |  A  |  B  |  C  |  D  |\n",
    "| :-----------------: | --- | --- | --- | --- |\n",
    "| **UK USERS**        | 50  | 100 | 180 | 70  |\n",
    "| **EXPECTED**        | 60  | 80  | 180 | 80  |\n",
    "| $\\frac{(E-O)^2}{E}$ | 1.67| 5.00| 0.00| 1.25|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This gives $\\chi^2 \\approx 1.67\t+ 5.00 + 0.00 + 1.25 = 7.92$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Determine p-value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Our last step is to determine the p-value via the $\\chi^2$ distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "One consideration is the _degrees of freedom_ (think back to our $t$-distribution). But how do we calculate the degrees of freedom here?\n",
    "\n",
    "Well, the **degrees of freedom** are really related to **how many categories/groups** we used (number of categories minus 1: $df = k-1$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "So in this case $df = 3$ and gives this distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "degrees_of_freedom = 3\n",
    "x = np.linspace(\n",
    "        stats.chi2.ppf(0.000001, degrees_of_freedom),\n",
    "        stats.chi2.ppf(0.9999, degrees_of_freedom), \n",
    "        500\n",
    ")\n",
    "\n",
    "f, ax = plt.subplots()\n",
    "ax.set_title('chi^2, 3 df')\n",
    "ax.plot(x, stats.chi2.pdf(x, degrees_of_freedom), 'r-', lw=5)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> Notice we used [`scipy.stats.chi2`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chi2.html) to generate the PDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Well, we also know our $\\chi^2$ statistic is $7.92$ so let's plot that too so we can see how much area under the is more extreme than our statistic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "chisq_stat = 7.92\n",
    "\n",
    "f, ax = plt.subplots()\n",
    "ax.set_title('chi^2 w/ df=3')\n",
    "ax.plot(x, stats.chi2.pdf(x, degrees_of_freedom), 'r-', lw=5)\n",
    "# Chi-square statistic\n",
    "ax.axvline(chisq_stat, ls='--', c='b', label='chi^2=7.92')\n",
    "ax.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This looks pretty small, but let's calculate the p-value to be sure. (Note we can use [`scipy.stats.chi2`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chi2.html) again to calculate the p-value of the distribution.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Note that we subtract since we want the area to the right of the statistic\n",
    "p = 1 - stats.chi2.cdf(chisq_stat, df=degrees_of_freedom)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.chi2.sf(chisq_stat, df=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "So not bad! For a significance level of $\\alpha=0.05$, we would say this is significantly different!\n",
    "\n",
    "So we can tell the company that, from the data provided, it appears that there is a statistically significant difference between U.S. and U.K. users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## But I'm Lazy Like a Fox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "As we saw before, if it's common enough someone probably already coded this up. Turns out there's a SciPy function [`scipy.stats.chisquare`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chisquare.html) that does this whole thing for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "observations = [50, 100, 180, 70]\n",
    "expectations = [60, 80, 180, 80]\n",
    "\n",
    "result = stats.chisquare(f_obs=observations, f_exp=expectations)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Sure enough, we get about the same values as we did by hand (but with a lot less work!)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
